#version: '3.9'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15
    container_name: postgres_db
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - data_network

  # MinIO for Object Storage
  minio:
    image: minio/minio
    container_name: minio_storage
    command: server --console-address ":9001" /data
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports:
      - "9000:9000"  # S3 API
      - "9001:9001"  # Web UI
    volumes:
      - minio_data:/data
    networks:
      - data_network

  # Kafka for Streaming Data
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_CLIENT_PORT}
    ports:
      - "2181:2181"
    networks:
      - data_network

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka_broker
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}
      KAFKA_ZOOKEEPER_CONNECT: ${KAFKA_ZOOKEEPER_CONNECT}
      KAFKA_ADVERTISED_LISTENERS: ${KAFKA_ADVERTISED_LISTENERS}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
    ports:
      - "9092:9092"
    networks:
      - data_network

  # Apache Airflow for Workflow Orchestration
  airflow:
    image: apache/airflow:2.7.0
    container_name: airflow
    restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}
    ports:
      - "8080:8080"
    volumes:
      - airflow_dags:/opt/airflow/dags
    networks:
      - data_network

  # Apache Spark for Distributed Data Processing
  spark-master:
    image: bitnami/spark:latest
    container_name: spark_master
    environment:
      SPARK_MODE: ${SPARK_MODE}
    ports:
      - "7077:7077"
      - "8081:8080"
    networks:
      - data_network

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark_worker
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: ${SPARK_MODE}
      SPARK_MASTER_URL: ${SPARK_MASTER_URL}
    networks:
      - data_network

  # Metabase for Business Intelligence
  metabase:
    image: metabase/metabase
    container_name: metabase
    ports:
      - "3000:3000"
    networks:
      - data_network

  # Jupyter Notebook for Data Analysis
  jupyter:
    image: jupyter/datascience-notebook
    container_name: jupyter_notebook
    ports:
      - "8888:8888"
    volumes:
      - jupyter_data:/home/jovyan/work
    networks:
      - data_network

  # Grafana for monitoring
  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GF_SECURITY_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GF_SECURITY_ADMIN_PASSWORD}
    networks:
      - data_network

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    restart: always
    depends_on:
      - postgres
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - "5050:80"
    networks:
      - data_network

volumes:
  postgres_data:
  minio_data:
  airflow_dags:
  jupyter_data:

networks:
  data_network:
    driver: bridge
